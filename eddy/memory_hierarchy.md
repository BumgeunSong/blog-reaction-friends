# 메모리 계층 뽀개기

거대한 도서관을 생각해보자. 이 도서관은 수백년 된 고서부터 신간까지, 수십만권의 책을 보관하고 있다. 도서관은 책을 어떤 방식으로 보관하고 있을까?

책꽂이에다 꽂아놓겠지. 쉽게 생각하면 그렇지만 자세히 들여다보면 그렇지 않다.

사람들이 자주 찾는 책이나 신간은 훨씬 더 잘보이는 곳에 배치되어있고, 쉽게 찾을 수 있도록 책 등이 아닌 책 표지를 꺼내놓는다.

사람들이 잘 찾지 않는 책이나 오래된 책들은 일반 서가가 아닌, 별도의 서고에 집어넣는다. 이런 서고는 공간 효율적으로 많은 책을 저장할 수 있는 특수한 서가로 이뤄져있다. 정말 큰 도서관은 보통 사람들이 들어갈 수 없는 서고가 수십개씩 있는 경우도 있다.

책을 보관할 수 있는 물리적인 공간은 한정돼있고, 수많은 책 중, 원하는 책을 쉽게 찾을 수 있어야하기 때문이다.

컴퓨터에 저장된 데이터도 마찬가지다. 컴퓨터의 저장 공간도 여러 층으로 나뉘어 있다. 

CPU 안의 레지스터는 가장 많이 사용하는 데이터를 저장하며, 매우 빠르게 데이터를 가져올 수 있다. CPU 옆에 있는, 작지만 빠른 캐시 메모리가 있다. 비교적 더 느린 메인 메모리와 CPU 사이의 중간 다리 역할을 한다. 

메인 메모리는 또 자기보다 더 느린 디스크나 외부 저장소의 중간 다리 역할을 한다.

모든 컴퓨팅 시스템에 이런 식으로 계층이 형성되는 이유는 2가지 특성 때문이다.

1. 저장 매체의 가격, 성능 트레이드 오프
2. 대부분의 프로그램이 가지는 지역성

이 2가지에 대해서는 뒤에 좀 더 자세히 설명하자.


## 프로그래머가 이걸 알아야하는 이유

단순하다. 메모리 계층 구조는 애플리케이션 성능에 아주 큰 영향을 미친다. 우리가 사용하려는 데이터가 어떤 층에 저장돼있냐에 따라서 프로그램의 성능은 수십배 - 수천만배까지 차이가 난다.

메모리 접근 속도는 CPU의 계산 속도가 증가하는만큼 빠르게 증가하고 있지 않다. 따라서 메모리에서 데이터를 가져오는 시간은 전체 프로그램의 성능을 크게 좌우하는 요소다.

즉, 프로그램의 성능을 이해하려면 메모리 계층을 잘 알아야 한다.

이번 글에서는 메모리 계층과 캐싱의 원리를 알아보자. 이 글을 다 읽고 나면 메모리 접근 속도의 근본 원리를 이해하는 개발자가 될 수 있을 것이다!


## 1. 저장 매체

메모리 계층이 생기는 첫번째 이유. 저장 매체 기술에 대해 알아보자.

당연한 말이지만, 컴퓨터에는 데이터를 저장하고 유지할 공간이 필요하다. 컴퓨터는 0과 1이라는 비트 정보를 저장하기 위해서 다양한 도구를 쓴다. 

그 중 가장 중요한 3개가 RAM, ROM, 디스크다.

![Storage_tech]

## 1. RAM
RAM에는 크게 2가지가 있다.

Random Access Memory이다. Random Access는 순차적 접근의 반대말이다. 몇번째에 있는지 알면 즉시 거기로 가서 값을 읽어올 수 있다. 데이터 접근이 빠르다. 

RAM은 휘발성 메모리다. 전기 공급이 끊어지면 다 날아간다. 


### Static RAM (SRAM)
가장 빠르고 비싼 메모리. 메모리계의 포르쉐라고 할 수 있다.

컴퓨터에서는 CPU 내부에 있는 캐시 메모리에 사용된다. 

SRAM은 6개의 트랜지스터로 만든 플립플롭이라는 회로에 하나의 비트를 저장한다. 트랜지스터가 6개 사용되기 때문에 밀도를 높이기가 어렵고 가격이 비싸다.

SRAM은 전기가 들어오는 동안에는 기록된 비트 값이 안정적으로 유지된다. 전기적 노이즈 같은 게 있어도 끄떡없다.

반대로 끄떡있는 녀석은...

### Dynamic RAM (DRAM)

DRAM이다. 

DRAM은 SRAM보다 싸고 많은 양을 담을 수 있다. 

캐시 메모리보다 더 용량이 큰 주 기억 장치 (메인 메모리)에 사용되는 저장 기술이다.

우리가 프로그램을 실행시키면, DRAM으로 만들어진 메인 메모리에 공간이 할당되는 것이다.

우리가 흔히 컴퓨터를 살 때 램 몇 기가야? 라고 묻는다. 그 때 램이 DRAM이다. 보통 4GB에서 32GB 사이의 용량을 가진다.

(참고로 우리나라 시가총액 1,2위 삼성전자와 SK 하이닉스의 주력 상품이 바로 이 DRAM이다. 전세계 DRAM의 약 75%는 Made in Korea이며, DRAM은 대한민국 최대의 수출품이다.)

DRAM에 많은 양의 데이터가 들어가는 이유는, '캐파시터'라고 하는 아주 작은 상자에 전자를 담기 때문이다. 캐파시터 전자가 있으면 1, 아니면 0으로 비트를 표현한다. 

트랜지스터를 1개 사용해서 캐파시터 뚜껑을 덮어서 상태를 유지한다.

캐파시터는 작고 트랜지스터를 하나만 사용하기 때문에, 밀도를 매우 높일 수 있고, 가격도 SRAM보다 저렴하다.

하지만 문제는 이 캐파시터의 전하가 시간이 지나면 새어나간다. 방전된다. 시간이 지나면 값이 사라진다. 

마치 모래 위에 쓴 글씨처럼 말이다. 

안정적인 SRAM과 달리 계속 변화한다고 해서 Dynamic RAM이라는 이름이 붙었다.

DRAM은 방전되어 내용이 사라지기 전에 충전을 다시 해줘야 한다.
DRAM의 전하가 유지되는 시간은 10MS에서 100MS 정도다. 0.01초에서 0.1초만 지나면 내용이 사라진다.

> 아니 그런 걸 쓸수가 있나?

하지만 우리의 시간과 컴퓨터의 시간은 다르기 때문에 괜찮다.컴퓨터의 클락 사이클은 나노세컨드 (십억분의 1초)이다.


### SRAM과 DRAM의 차이
빠르고 안정적이지만, 비싸서 조금밖에 못쓰는 게 SRAM.
덜 빠르고 불안정하지만, 싸서 많이 쓸 수 있는 게 DRAM.

## 2. ROM

ROM은 비휘발성 메모리다. RAM만큼 데이터를 빠르게 가져올 수 있진 않지만, 전원이 꺼져도 정보를 저장해주는 믿을 수 있는 친구다. 

즉, 전기가 들어오지 않아도 계속해서 정보를 유지해야 한다. 
전기가 공급되지 않아도, 정보를 저장하는 방법은 시대를 걸쳐서 여러가지 방법이 진화해왔다.

최초의 ROM은 천공 카드라고 한다. OMR 카드 같이 생겼는데 여기에 구멍을 뚫어서 비트를 표시했다. 

그 다음에는 점점 더 효율적인 ROM들이 등장했다. 프로그래밍이 가능한 ROM (PROM), 쓴 데이터를 지울 수 있는 PROM (ERPOM), 전기적으로 작동하는 EPROM (EEPROM) 등.

### 플래시 메모리
EEPROM 중에서도 가장 많이 쓰이는 기술이 1980년대 일본도시바 사에서 개발한 플래시 메모리다.
플래시 메모리는 비휘발성인데도 내구성이 매우 강하고, 읽기 속도가 빠르고, 전력도 적게 쓴다. 
우리가 사용하는 USB 드라이브, 디지털 카메라, 스마트폰, 노트북... 다 이 플래시 메모리를 사용한다.


## 3. Disk Drive

윈도우를 써봤다면, 내 컴퓨터 안에 C 드라이브, D 드라이브를 본 적이 있을 거다. 이게 바로 디스크 드라이브다.

디스크는 앞에 나온 저장 매체보다 훨씬 느리다. 얼마나 느리냐면, DRAM보다 수십만배 가까이 느리다.

대신 디스크는 전원이 꺼져도 데이터가 사라지지 않으며, 무엇보다 엄청나게 많은 양의 데이터를 저장할 수 있다. DRAM의 저장 용량은 보통 커야 수십 GB인 반면 디스크는 수천 GB 크기다. 

자주 꺼내기는 힘들지만 양은 많이 들어가는 창고 느낌이랄까?

DISK에는 전통적 기술인 HDD와 최근 대세인 SSD가 있다.

### 하드 디스크 드라이브 (HDD)

LP판을 본 적이 있는가? LP판을 보면 판에 미세한 홈이 파여있다. 이 홈들이 음악 데이터를 저장하고 있다. 그리고 턴테이블에 LP를 올리면, 바늘이 홈을 읽어서 음악을 재생한다.

![vinyl](https://cf.shopee.sg/file/5b3587e6ec110cc3aacaf5eb890fcd7d)

HDD도 같다. 플래터라고 부르는 원판이 있다. 이 원판에 자성으로 데이터를 기록하도록 돼있다. 

이 원판은 모터로 빠르게 회전한다. 그 위에 헤드라는 녀석이 데이터를 읽고 쓴다.

![HDD](https://m.media-amazon.com/images/I/81yHZDfM3GL._AC_SL1500_.jpg)

물리적인 속도에 한계가 있고, 데이터가 저장된 위치로 계속 헤드가 이동하는 데 시간이 필요하기 때문에, 상당히 접근 속도가 드리다.

반면에 기록 밀도는 매우 높아서 많은 양의 데이터가 들어가고, 용량당 가격이 무지막지 싸다는 게 장점이다.

(** TMI: '하드' 디스크라고 불리는 이유는, 플로피 디스크라는 저장 장치와 구분하기 위해서였다. 플로피 디스크는 구부러지는 재질이었기 때문.)

### 솔리드 스테이트 디스크 (SSD)

SSD는 최근 새롭게 떠오르는 기술이다. 하드 디스크보다 훨씬 더 빠르고, 내구성도 좋다. 

SSD가 어떻게 그렇게 빠를 수 있냐, 바로 위에서 말했던 플래시 메모리를 사용한 디스크라서 그렇다. 

기계식 디스크 대신 플래시 메모리 여러개를 담아 디스크로 패키징한 것이다. 보조 기억 장치로 쓰인다 뿐이지, HDD와는 사실 전혀 다르다.

물리적인 회전 없이 전자적인 방식으로 데이터를 읽고 쓴다. 물리적으로 움직이는 부품이 없으니 소음도 없고, 전력이나 내구성도 좋다. 접근 속도도 훨씬 빠르다.

가격면에서 아직 하드 디스크보다 비싸다. SSD가격은 빠르게 싸지고 있고, 이 차이는 거의 줄어들고 있다.

덕분에 휴대성이 중요한 디바이스에서는 완전히 하드 디스크를 대체했다.


## 여기까지 중요한 점

자, 여기까지 주요 저장 매체 기술을 알아봤다.
여기서 가장 중요한 시사점 2가지만 꼽아보겠다.

다 안 읽고 스크롤 내렸어도, 이 2가지만 기억하면 된다.

1. 저장 매체의 가격과 성능은 반비례 관계다.

'용량당 가격'과 '성능'은 반비례한다. SRAM - DRAM - SSD - HDD 로 갈 수록, 가격은 싸지고 용량은 늘어나지만, 반대로 접근 속도가 느려진다.

SRAM은 HDD보다 수백만배 빠르다. 용량은 수십만배 적다.

우리는 데이터를 많이 저장하는 것도 필요하고, 빠른 것도 중요하다. 각 저장 매체는 다 명확한 장단점이 존재한다.

2. 저장매체의 성능은 CPU 성능보다 느리게 개선되고 있다.

<컴퓨팅 시스템> 책을 보면 1985년부터 2015년까지 메모리와 CPU 성능 변화를 비교한 표가 나온다. 

30년 전과 비교해볼때, 
SRAM의 접근 속도는 100배 빨라졌다.
DRAM의 접근 속도는 10배 빨라졌다. 
DISK의 접근 속도는 25배 빨라졌다.

하지만 CPU의 실질 속도 (사이클 타임)은 2000배 증가했다.

저장 매체의 '가격'은 빠르게 떨어지고 있지만, 그럼에도 속도 측면에서는 메모리-프로세서 갭이 커지고 있다.

따라서 CPU가 계산을 하고, 메모리에서 값을 가져와서 CPU가 계산을 하는 게 컴퓨터의 일이니까, 컴퓨터의 성능을 높이려면, 메모리 속도를 최대한 효율화해야한다. 

저장매체의 트레이드 오프를 고려하면서도 메모리 접근 속도를 높이려면 어떻게 해야할까? 

그래서 다음에 나올 지역성과 캐싱이 중요해진다.



## 2. 지역성

인간은 익숙한 것에 계속 손이 가는 경향이 있다. 옷도 입던 스타일과 비슷한 옷이 편하다. 음식도 자주 먹던 음식을 많이 찾는다.

물론 프로그램에 취향은 없겠지만. 프로그램도 데이터를 찾을 때 비슷한 경향을 보인다. 최근에 찾은 데이터나, 최근에 찾은 데이터 근처의 데이터를 많이 참조한다.

이걸 지역성(Locality)라고 한다.

아주 단순한 원리다. 하지만 굉장히 보편적이고 중요한 개념이다. 하드웨어, 소프트웨어에 걸쳐서 어마어마한 영향을 끼쳤다.

### 시간 지역성

최근에 참조된 메모리 위치를 다시 참조할 가능성이 높은 경향을 시간 지역성이라고 한다.

뒤집어 말하면, 동일한 변수를 반복적으로 참조하는 프로그램은 시간 지역성이 있다.

### 공간 지역성

최근에 참조한 메모리 위치 '근처의' 메모리를 다시 참조할 가능성이 높다. 이건 공간적인 개념이라 공간 지역성이라고 한다.

메모리 주소를 차례차례 참조하는 프로그램은 공간 지역성이 있다. 이를 테면 배열의 순회를 돈다든지.


## 지역성이 있는 코드 (캐시 친화적 코드)

프로그래머라면 지역성(Locality)의 개념을 알아야 한다. 지역성이 높은 코드는 지역성이 낮은 코드보다 훨씬 실행 속도가 빠르기 때문이다.

프로그램이 지역성이 있다고 가정하기 때문에, 컴퓨팅 시스템은 이걸 활용해서 최적화를 하고 있다. 현대 하드웨어, 운영체제, 어플리케이션, 인터넷에 이르기까지 컴퓨팅 시스템의 모든 레벨은 최근에 사용한 데이터, 최근에 사용한 위치 근처의 데이터를 빨리 접근할 수 있도록 따로 저장해둔다. 이것을 캐싱이라고 한다.

지역성이 높은 코드는 캐시를 더 활용할 수 있고, 그 결과 실행 속도가 빨라진다.

어떤 코드가 지역성이 있는 코드일까?

코드를 보고 대략적인 감을 잡을 수 있으면 좋다.

같은 변수를 반복적으로 참조하거나, 연속적으로 저장된 데이터를 순차적으로 참조하는 코드가 지역성이 높을 것이다.

루프를 사용하는 코드는 높은 시간, 공간 지역성을 가진다.

순차 참조 패턴을 보이는 코드 중에서도, 참조의 간격이 작을수록 좋은 지역성을 가진 코드다.

예를 들면, 배열의 인덱스를 +1 시켜가면서 도는 루프문이 +3 씩 도는 루프문보다 지역성이 좋다.

그렇다면 다음 이중 루프 중에서 어떤 것이 더 지역성이 높을까? 2차원 배열을 돌면서 곱하기 2를 하는 코드다.

```javascript
// 1번
for (i = 0; i < columns; i += 1) {
  for (j = 0; j < rows; j += 1) {
    arr[j][i] *= 2
  }
}
```

```javascript
// 2번
for (i = 0; i < columns; i += 1) {
  for (j = 0; j < rows; j += 1) {
    arr[i][j] *= 2
  }
}
```

차이를 발견했는가?

아주 조그만 차이 같지만, 2번이 더 지역성이 좋은 코드다.

1번은 [0,0] - [1,0] - [2,0] 순으로 같은 칼럼의 위치부터 참조한다.
2번은 [0,0] - [0,1] - [0,2] 순으로 같은 행을 차례로 참조한다.

배열은 메모리 상에 연속적인 형태로 저장된다. 배열의 인덱스와 메모리 위치를 단순화해본다면 이 순서다.

(0,0) - (0,1) - (0,2) - (1,0) - (1,1) - (1,2) - (2,0) - (2,1) - (2,2)

그러니까 2번 루프는 차례대로 도는 반면, 1번 루프는 위치상 이리 저리 점프를 하게 된다.

2번이 더 좋은 시간 지역성을 가진다.

### 퀵 정렬이 빠른 이유

합병 정렬, 힙 정렬, 퀵 정렬은 모두 시간복잡도가 `O(N log N)`이다. 

그런데 실제 실행 속도는 일반적으로 퀵 정렬이 가장 빠르다. 그래서 퀵 정렬이라는 이름이 붙었다.

그 이유는 바로 퀵 정렬의 구현 코드가 힙 정렬이나 머지 정렬보다 지역성이 높기 때문이다.

퀵 정렬은 pivot을 고르고 파티셔닝(스왑)을 할때 전체 배열을 순차적으로 참조하거나, 같은 pivot 위치를 계속 참조한다.

반면 힙 정렬은 완전 이진 트리를 구현하기 때문에 힙을 잡기 위해 swap을 할때 계속 곱하기 2를 한 자리를 참조한다.

머지 정렬은 아예 새로운 메모리 위치에 배열을 만들기 때문에 지역성이 적다.

이처럼 지역성이 있는 코드와 아닌 코드에 대한 감을 잡아두면, 실제 성능을 예측하는 데 도움이 된다.




## 3. 메모리 계층과 캐싱