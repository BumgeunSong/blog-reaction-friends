# 메모리 계층 뽀개기

거대한 도서관을 생각해보자. 이 도서관은 수백년 된 고서부터 신간까지, 수십만권의 책을 보관하고 있다. 도서관은 책을 어떤 방식으로 보관하고 있을까?

> 책꽂이에다 꽂아놓겠지? 

쉽게 생각하면 그렇지만 자세히 들여다보면 그렇지 않다.

사람들이 자주 찾는 책이나 신간은 훨씬 더 잘보이는 곳에 배치되어있고, 쉽게 찾을 수 있도록 책 등이 아닌 책 표지를 꺼내놓는다.

사람들이 잘 찾지 않는 책이나 오래된 책들은 일반 서가가 아닌, 별도의 서고에 집어넣는다. 이런 서고는 공간 효율적으로 많은 책을 저장할 수 있는 특수한 서가로 이뤄져있다. 정말 큰 도서관은 보통 사람들이 들어갈 수 없는 서고가 수십개씩 있는 경우도 있다.

책을 보관할 수 있는 물리적인 공간은 한정돼있고, 수많은 책 중, 원하는 책을 쉽게 찾을 수 있어야하기 때문이다.

컴퓨터에 저장된 데이터도 마찬가지다. 컴퓨터의 저장 공간도 여러 층으로 나뉘어 있다. 

CPU 안의 레지스터는 가장 많이 사용하는 데이터를 저장하며, 매우 빠르게 데이터를 가져올 수 있다. CPU 옆에 있는, 작지만 빠른 캐시 메모리가 있다. 비교적 더 느린 메인 메모리와 CPU 사이의 중간 다리 역할을 한다. 

메인 메모리는 또 자기보다 더 느린 디스크나 외부 저장소의 중간 다리 역할을 한다.

모든 컴퓨팅 시스템에 이런 식으로 계층이 형성되는 이유는 2가지 특성 때문이다.

1. 저장 매체의 가격, 성능 트레이드 오프
2. 대부분의 프로그램이 가지는 지역성

이 2가지에 대해서는 뒤에 좀 더 자세히 설명하자.


## 프로그래머가 이걸 알아야하는 이유

단순하다. 메모리 계층 구조는 애플리케이션 성능에 아주 큰 영향을 미친다. 우리가 사용하려는 데이터가 어떤 층에 저장돼있냐에 따라서 프로그램의 성능은 수십배 - 수천만배까지 차이가 난다.

메모리 접근 속도는 CPU의 계산 속도가 증가하는만큼 빠르게 증가하고 있지 않다. 따라서 메모리에서 데이터를 가져오는 시간은 전체 프로그램의 성능을 크게 좌우하는 요소다.

즉, 프로그램의 성능을 이해하려면 메모리 계층을 잘 알아야 한다.

이번 글에서는 메모리 계층과 캐싱의 원리를 알아보자. 이 글을 다 읽고 나면 메모리 접근 속도의 근본 원리를 이해하는 개발자가 될 수 있을 것이다!


## 1. 저장 매체

## 2. 지역성

## 3. 메모리 계층

## 4. 캐싱